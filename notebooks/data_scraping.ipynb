{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import jsonlines\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "\n",
    "JSON_FILE_PATH = 'C:\\\\Users\\\\Stoja\\\\python_projects\\\\kp_semantic_search\\\\ads_json\\\\'\n",
    "URL_FILE_PATH = 'C:\\\\Users\\\\Stoja\\\\python_projects\\\\kp_semantic_search\\\\ads_json\\\\urls.txt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# func for extracting ad name\n",
    "def extract_ad_name(driver):\n",
    "    try:\n",
    "        name = driver.find_element(By.XPATH, '//*[@id=\"__next\"]/div/div[3]/div/div/div[2]/section[1]/div[2]/section[1]/div[1]/h1').text\n",
    "        try:\n",
    "            name.replace('\"', 'inc')\n",
    "            return name or ''\n",
    "        except:\n",
    "            return name\n",
    "    except:\n",
    "        return 'Nepoznato'\n",
    "#func for extracting category\n",
    "def extract_cat(driver):\n",
    "    try:\n",
    "        return driver.find_element(By.XPATH,'//*[@id=\"__next\"]/div/div[3]/div/div/div[2]/section[1]/div[1]/div/div[1]/span/div[1]/a[1]').text\n",
    "    except:\n",
    "        return 'Nepoznato'\n",
    "\n",
    "#func for extracting subcategory\n",
    "def extract_sub_cat(driver):\n",
    "    try:\n",
    "        return driver.find_element(By.XPATH, '//*[@id=\"__next\"]/div/div[3]/div/div/div[2]/section[1]/div[1]/div/div[1]/span/div[1]/a[2]').text\n",
    "    except:\n",
    "        return 'Nepoznato'\n",
    "\n",
    "#func for extracting id of the ad\n",
    "def extract_ad_id(driver):\n",
    "    try:\n",
    "        return driver.find_element(By.XPATH, '//*[@id=\"__next\"]/div/div[3]/div/div/div[2]/section[1]/div[1]/div/div[1]/span/div[1]/span').text\n",
    "    except:\n",
    "        return 'Nepoznato'\n",
    "\n",
    "#func for extracting username\n",
    "def extract_user(driver):\n",
    "    try:\n",
    "        return driver.find_element(By.XPATH, '//*[@id=\"__next\"]/div/div[3]/div/div/div[2]/section[1]/div[2]/section[2]/section/div[2]/div[1]/span[2]').text\n",
    "    except: \n",
    "        return 'Nepoznato'\n",
    "\n",
    "#func for extracting membership\n",
    "def extract_membership(driver):\n",
    "    try:\n",
    "        return driver.find_element(By.XPATH, '//*[@id=\"__next\"]/div/div[3]/div/div/div[2]/section[1]/div[2]/section[2]/section/div[2]/div[2]/div/div[1]').text\n",
    "    except:\n",
    "        return 'Nepoznato'\n",
    "\n",
    "#func for extracting place-from\n",
    "def extract_place(driver):\n",
    "    try:\n",
    "        return driver.find_element(By.XPATH, '//*[@id=\"__next\"]/div/div[3]/div/div/div[2]/section[1]/div[2]/section[2]/section/div[2]/div[2]/div/div[2]').text\n",
    "    except:\n",
    "        return 'Nepoznato'\n",
    "\n",
    "#func for extracting good reviews\n",
    "def extract_positive_reviews(driver):\n",
    "    try:\n",
    "        return driver.find_element(By.CLASS_NAME, 'ReviewThumbLinks_positive__uoQ7Z').text\n",
    "    except:\n",
    "        return 'Nepoznato'\n",
    "\n",
    "\n",
    "#func for extracting bad reviews\n",
    "def extract_negative_reviews(driver):\n",
    "    try:\n",
    "        return driver.find_element(By.CLASS_NAME, 'ReviewThumbLinks_negative__c9WWb').text\n",
    "    except:\n",
    "        return 'Nepoznato'\n",
    "\n",
    "#func for extracting price\n",
    "def extract_price(driver):\n",
    "    try:\n",
    "        return driver.find_element(By.XPATH, '//*[@id=\"__next\"]/div/div[3]/div/div/div[2]/section[1]/div[2]/section[1]/div[3]/div[2]/div[1]/h2').text\n",
    "    except:\n",
    "        return 'Nepoznato'\n",
    "\n",
    "#func for extracting condition\n",
    "def extract_condition(driver):\n",
    "    try:\n",
    "        return driver.find_element(By.XPATH, '//*[@id=\"__next\"]/div/div[3]/div/div/div[2]/section[1]/div[2]/section[1]/div[1]/div').text\n",
    "    except: return 'Nepoznato'\n",
    "    \n",
    "\n",
    "#func for extracting images\n",
    "def extract_images(driver):\n",
    "    try:\n",
    "        images = []\n",
    "        elements = driver.find_elements(By.CLASS_NAME,'GalleryThumbnail_imageGalleryThumbnailInner___ou1n')\n",
    "        for element in elements:\n",
    "            image = element.find_element(By.TAG_NAME, 'img').get_attribute(\"src\")\n",
    "            images.append(image)\n",
    "        return images\n",
    "    except:\n",
    "        return 'Nepoznato'\n",
    "\n",
    "#func for extracting description\n",
    "def extract_desc(driver):\n",
    "    try:\n",
    "        element =  driver.find_element(By.XPATH, '//*[@id=\"__next\"]/div/div[3]/div/div/div[2]/section[1]/div[3]')\n",
    "        html_content = element.get_attribute('innerHTML')\n",
    "\n",
    "    # Use BeautifulSoup to parse the HTML content and extract text\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "        text_content = soup.get_text(separator='\\n')\n",
    "        return text_content\n",
    "    except:\n",
    "        return 'Nepoznato'\n",
    "    \n",
    "def extract_url(driver):\n",
    "    try:\n",
    "        return driver.current_url\n",
    "    except:\n",
    "        return 'Nepoznato'\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#func for calling all extractor functions\n",
    "\n",
    "def call(driver):\n",
    "    ad_name = extract_ad_name(driver)\n",
    "    ad_id = extract_ad_id(driver)\n",
    "    condition = extract_condition(driver)\n",
    "    category = extract_cat(driver)\n",
    "    sub_cat = extract_sub_cat(driver)\n",
    "    price = extract_price(driver)\n",
    "    user = extract_user(driver)\n",
    "    membership = extract_membership(driver)\n",
    "    place = extract_place(driver)\n",
    "    good_reviews = extract_positive_reviews(driver)\n",
    "    bad_reviews = extract_negative_reviews(driver)\n",
    "    images = extract_images(driver)\n",
    "    desc = extract_desc(driver)\n",
    "    url = extract_url(driver)\n",
    "\n",
    "    data = {\n",
    "    'ad': {\n",
    "        'ad_url': url,\n",
    "        'ad_name': ad_name,\n",
    "        'ad_id': ad_id,\n",
    "        'price': price,\n",
    "        'condition': condition,\n",
    "        'category': category,\n",
    "        'sub_cat': sub_cat,\n",
    "        'description': desc,\n",
    "        'images': images\n",
    "         },\n",
    "    'user': {\n",
    "        'name': user,\n",
    "        'membership': membership,\n",
    "        'place': place,\n",
    "        'good_reviews': good_reviews,\n",
    "        'bad_reviews': bad_reviews\n",
    "        }\n",
    "    }\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_json(data):\n",
    "#     with open(JSON_FILE_PATH, 'w') as json_file:\n",
    "#         json.dump(data, json_file, indent=4)\n",
    "#         json_file.write('\\n')\n",
    "\n",
    "def load_urls():\n",
    "    try:\n",
    "        with open(URL_FILE_PATH, 'r') as file:\n",
    "            content = file.read()\n",
    "            url_list = content.strip().replace('\\n', '').split(',')\n",
    "            return url_list\n",
    "    except FileNotFoundError:\n",
    "        print('File not found!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = 'ads1.jsonl'\n",
    "file2 = 'ads2.jsonl'\n",
    "file3 = 'ads3.jsonl'\n",
    "file4 = 'ads4.jsonl'\n",
    "\n",
    "url_list = load_urls()\n",
    "list1 = url_list[:25]\n",
    "list2 = url_list[25:50]\n",
    "list3 = url_list[50:75]\n",
    "list4 = url_list[75:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "25\n",
      "25\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "print(len(list1))\n",
    "print(len(list2))\n",
    "print(len(list3))\n",
    "print(len(list4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup ChromeDriver\n",
    "def create_jsonl(list, file_name):\n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    driver = webdriver.Chrome(service=service)\n",
    "\n",
    "    with jsonlines.open(JSON_FILE_PATH  + file_name, 'w') as json_file:    \n",
    "        for url in list:\n",
    "            driver.get(url)\n",
    "\n",
    "            # Wait for the page to load completely\n",
    "            time.sleep(5)  # Adjust time as necessary\n",
    "\n",
    "            # Extract the page source\n",
    "            data = call(driver)\n",
    "            json_file.write(data)\n",
    "\n",
    "    # Close the browser\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_jsonl(list1, file1)\n",
    "# create_jsonl(list2, file2)\n",
    "# create_jsonl(list3, file3)\n",
    "# create_jsonl(list4, file4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kpss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
